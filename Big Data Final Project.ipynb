{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIG DATA FINAL PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Risk Modeling (Lending Club)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We will focus on credit modelling, a well known data science problem that focuses on modeling a borrower's credit risk. Credit has played a key role in the economy for centuries and some form of credit has existed since the beginning of commerce. We'll be working with financial lending data from Lending Club. Lending Club is a marketplace for personal loans that matches borrowers who are seeking a loan with investors looking to lend money and make a return. \n",
    "\n",
    "+ Each borrower fills out a comprehensive application, providing their past financial history, the reason for the loan, and more. Lending Club evaluates each borrower's credit score using past historical data (and their own data science process!) and assign an interest rate to the borrower. The interest rate is the percent in addition to the requested loan amount the borrower has to pay back. Lending Club also tries to verify each piece of information the borrower provides but it can't always verify all of the information (usually for regulation reasons).\n",
    "\n",
    "+ A higher interest rate means that the borrower is riskier and more unlikely to pay back the loan while a lower interest rate means that the borrower has a good credit history is more likely to pay back the loan. The interest rates range from 5.32% all the way to 30.99% and each borrower is given a grade according to the interest rate they were assigned. If the borrower accepts the interest rate, then the loan is listed on the Lending Club marketplace.\n",
    "\n",
    "+ Investors are primarily interested in receiveing a return on their investments. Approved loans are listed on the Lending Club website, where qualified investors can browse recently approved loans, the borrower's credit score, the purpose for the loan, and other information from the application. Once they're ready to back a loan, they select the amount of money they want to fund. Once a loan's requested amount is fully funded, the borrower receives the money they requested minus the origination fee that Lending Club charges.\n",
    "\n",
    "+ The borrower then makes monthly payments back to Lending Club either over 36 months or over 60 months. Lending Club redistributes these payments to the investors. This means that investors don't have to wait until the full amount is paid off to start to see money back. If a loan is fully paid off on time, the investors make a return which corresponds to the interest rate the borrower had to pay in addition the requested amount. Many loans aren't completely paid off on time, however, and some borrowers default on the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ While Lending Club has to be extremely savvy and rigorous with their credit modelling, investors on Lending Club need to be equally as savvy about determining which loans are more likely to be paid off. While at first, you may wonder why investors would put money into anything but low interest loans. The incentive investors have to back higher interest loans is, well, the higher interest! If investors believe the borrower can pay back the loan, even if he or she has a weak financial history, then investors can make more money through the larger additional amount the borrower has to pay.\n",
    "\n",
    "+ Most investors use a portfolio strategy to invest small amounts in many loans, with healthy mixes of low, medium, and interest loans. In this course, we'll focus on the mindset of a conservative investor who only wants to invest in the loans that have a good chance of being paid off on time. To do that, we'll need to first understand the features in the dataset and then experiment with building machine learning models that reliably predict if a loan will be paid off or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll focus on approved loans data from 2007 to 2011, since a good number of the loans have already finished. In the datasets for later years, many of the loans are current and still being paid off. The data has been sourced from Lending Club's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import tests as t\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us perform some basic data exploration to understand how the dataset looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007=pd.read_csv('loans_2007.csv',low_memory = False) # Reading the dataset on to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade    ...    last_pymnt_amnt  \\\n",
       "0   10.65%       162.87     B        B2    ...             171.62   \n",
       "1   15.27%        59.83     C        C4    ...             119.66   \n",
       "2   15.96%        84.33     C        C5    ...             649.91   \n",
       "3   13.49%       339.31     C        C1    ...             357.48   \n",
       "4   12.69%        67.79     B        B5    ...              67.79   \n",
       "\n",
       "  last_credit_pull_d collections_12_mths_ex_med  policy_code application_type  \\\n",
       "0           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "1           Sep-2013                        0.0          1.0       INDIVIDUAL   \n",
       "2           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "3           Apr-2016                        0.0          1.0       INDIVIDUAL   \n",
       "4           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "\n",
       "  acc_now_delinq chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies  \\\n",
       "0            0.0                      0.0         0.0                  0.0   \n",
       "1            0.0                      0.0         0.0                  0.0   \n",
       "2            0.0                      0.0         0.0                  0.0   \n",
       "3            0.0                      0.0         0.0                  0.0   \n",
       "4            0.0                      0.0         0.0                  0.0   \n",
       "\n",
       "  tax_liens  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>member_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loan_amnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>funded_amnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>funded_amnt_inv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>int_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>installment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sub_grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>emp_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>emp_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>home_ownership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>annual_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>verification_status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>issue_d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>loan_status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pymnt_plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>zip_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>addr_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>earliest_cr_line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>inq_last_6mths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>open_acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pub_rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>revol_bal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>revol_util</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>total_acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>initial_list_status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>out_prncp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>out_prncp_inv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>total_pymnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>total_pymnt_inv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>total_rec_prncp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>total_rec_int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>total_rec_late_fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>recoveries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>collection_recovery_fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>last_pymnt_d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>last_pymnt_amnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>last_credit_pull_d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>collections_12_mths_ex_med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>policy_code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>application_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>chargeoff_within_12_mths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>delinq_amnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>pub_rec_bankruptcies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tax_liens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0                           id\n",
       "1                    member_id\n",
       "2                    loan_amnt\n",
       "3                  funded_amnt\n",
       "4              funded_amnt_inv\n",
       "5                         term\n",
       "6                     int_rate\n",
       "7                  installment\n",
       "8                        grade\n",
       "9                    sub_grade\n",
       "10                   emp_title\n",
       "11                  emp_length\n",
       "12              home_ownership\n",
       "13                  annual_inc\n",
       "14         verification_status\n",
       "15                     issue_d\n",
       "16                 loan_status\n",
       "17                  pymnt_plan\n",
       "18                     purpose\n",
       "19                       title\n",
       "20                    zip_code\n",
       "21                  addr_state\n",
       "22                         dti\n",
       "23                 delinq_2yrs\n",
       "24            earliest_cr_line\n",
       "25              inq_last_6mths\n",
       "26                    open_acc\n",
       "27                     pub_rec\n",
       "28                   revol_bal\n",
       "29                  revol_util\n",
       "30                   total_acc\n",
       "31         initial_list_status\n",
       "32                   out_prncp\n",
       "33               out_prncp_inv\n",
       "34                 total_pymnt\n",
       "35             total_pymnt_inv\n",
       "36             total_rec_prncp\n",
       "37               total_rec_int\n",
       "38          total_rec_late_fee\n",
       "39                  recoveries\n",
       "40     collection_recovery_fee\n",
       "41                last_pymnt_d\n",
       "42             last_pymnt_amnt\n",
       "43          last_credit_pull_d\n",
       "44  collections_12_mths_ex_med\n",
       "45                 policy_code\n",
       "46            application_type\n",
       "47              acc_now_delinq\n",
       "48    chargeoff_within_12_mths\n",
       "49                 delinq_amnt\n",
       "50        pub_rec_bankruptcies\n",
       "51                   tax_liens"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007.head() # Gives the first 5 rows of the dataset with all columns\n",
    "pd.DataFrame(loans_2007.columns)  # This will print out a list of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataframe contains many columns and can be cumbersome to try to explore all at once. Let's break up the columns into 3 groups of 18 columns and use the data dictionary to become familiar with what each column represents. As we understand each feature, we want to pay attention to any features that:\n",
    "\n",
    "+ leak information from the future (after the loan has already been funded)\n",
    "+ don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club)\n",
    "+ formatted poorly and need to be cleaned up\n",
    "+ require more data or a lot of processing to turn into a useful feature\n",
    "+ contain redundant information\n",
    "+ We need to especially pay attention to data leakage, since it can cause our model to overfit. This is because the model would be using data about the target column that wouldn't be available when we're using the model on future loans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ After analyzing first 18 columns, we can conclude that the following features need to be removed:\n",
    "\n",
    "+ id: randomly generated field by Lending Club for unique identification purposes only\n",
    "+ member_id: also a randomly generated field by Lending Club for unique identification purposes only\n",
    "+ funded_amnt: leaks data from the future (after the loan is already started to be funded)\n",
    "+ funded_amnt_inv: also leaks data from the future (after the loan is already started to be funded)\n",
    "+ grade: contains redundant information as the interest rate column (int_rate)\n",
    "+ sub_grade: also contains redundant information as the interest rate column (int_rate)\n",
    "+ emp_title: requires other data and a lot of processing to potentially be useful\n",
    "+ issue_d: leaks data from the future (after the loan is already completed funded)\n",
    "+ Recall that Lending Club assigns a grade and a sub-grade based on the borrower's interest rate. While the grade and sub_grade values are categorical, the int_rate column contains continuous values, which are better suited for machine learning.\n",
    "\n",
    "+ Let's now drop these columns from the Dataframe before moving onto the next group of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007=loans_2007.drop(['id','member_id','funded_amnt','funded_amnt_inv','grade','sub_grade','emp_title','issue_d'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Within the next 18 group of columns, we need to drop the following columns:\n",
    "\n",
    "+ zip_code: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    "+ out_prncp: leaks data from the future, (after the loan already started to be paid off)\n",
    "+ out_prncp_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    "+ total_pymnt: also leaks data from the future, (after the loan already started to be paid off)\n",
    "+ total_pymnt_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    "+ total_rec_prncp: also leaks data from the future, (after the loan already started to be paid off)\n",
    "+ The out_prncp and out_prncp_inv both describe the outstanding principal amount for a loan, which is the remaining amount the borrower still owes. These 2 columns as well as the total_pymnt column describe properties of the loan after it's fully funded and started to be paid off. This information isn't available to an investor before the loan is fully funded and we don't want to include it in our model.\n",
    "\n",
    "+ Let's go ahead and remove these columns from the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007=loans_2007.drop(['zip_code','out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv','total_rec_prncp'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ In the last group of columns, we need to drop the following columns:\n",
    "\n",
    "+ total_rec_int: leaks data from the future, (after the loan already started to be paid off),\n",
    "+ total_rec_late_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "+ recoveries: also leaks data from the future, (after the loan already started to be paid off),\n",
    "+ collection_recovery_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "+ last_pymnt_d: also leaks data from the future, (after the loan already started to be paid off),\n",
    "+ last_pymnt_amnt: also leaks data from the future, (after the loan already started to be paid off).\n",
    "+ All of these columns leak data from the future, meaning that they're describing aspects of the loan after it's already been fully funded and started to be paid off by the borrower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007=loans_2007.drop(['total_rec_int','total_rec_late_fee','recoveries','collection_recovery_fee','last_pymnt_d','last_pymnt_amnt'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>...</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt        term int_rate  installment emp_length home_ownership  \\\n",
       "0     5000.0   36 months   10.65%       162.87  10+ years           RENT   \n",
       "\n",
       "   annual_inc verification_status loan_status pymnt_plan    ...      \\\n",
       "0     24000.0            Verified  Fully Paid          n    ...       \n",
       "\n",
       "  initial_list_status last_credit_pull_d collections_12_mths_ex_med  \\\n",
       "0                   f           Jun-2016                        0.0   \n",
       "\n",
       "   policy_code  application_type acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0          1.0        INDIVIDUAL            0.0                       0.0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
       "0          0.0                   0.0        0.0  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42538, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007.head(1)\n",
    "loans_2007.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Just by becoming familiar with the columns in the dataset, we were able to reduce the number of columns from 52 to 32 columns. We now need to decide on a target column that we want to use for modeling.\n",
    "\n",
    "+ We should use the loan_status column, since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values and we need to convert it to a numerical one for training a model. Let's explore the different values in this column and come up with a strategy for converting the values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fully Paid</th>\n",
       "      <td>33136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charged Off</th>\n",
       "      <td>5634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does not meet the credit policy. Status:Fully Paid</th>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current</th>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Does not meet the credit policy. Status:Charged Off</th>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Late (31-120 days)</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Grace Period</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Late (16-30 days)</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    loan_status\n",
       "Fully Paid                                                33136\n",
       "Charged Off                                                5634\n",
       "Does not meet the credit policy. Status:Fully Paid         1988\n",
       "Current                                                     961\n",
       "Does not meet the credit policy. Status:Charged...          761\n",
       "Late (31-120 days)                                           24\n",
       "In Grace Period                                              20\n",
       "Late (16-30 days)                                             8\n",
       "Default                                                       3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(loans_2007['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ From the investor's perspective, we're interested in trying to predict which loans will be paid off on time and which ones won't be. Only the Fully Paid and Charged Off values describe the final outcome of the loan. The other values describe loans that are still on going and where the jury is still out on if the borrower will pay back the loan on time or not. While the Default status resembles the Charged Off status, in Lending Club's eyes, loans that are charged off have essentially no chance of being repaid while default ones have a small chance.\n",
    "+ Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. Let's remove all the loans that don't contain either Fully Paid and Charged Off as the loan's status and then transform the Fully Paid values to 1 for the positive case and the Charged Off values to 0 for the negative case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007=loans_2007.loc[(loans_2007['loan_status']=='Fully Paid')|(loans_2007['loan_status']=='Charged Off')]\n",
    "loans_2007=loans_2007.replace({'Fully Paid':1,'Charged Off':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Let's look for any columns that contain only one unique value and remove them. These columns won't be useful for the model since they don't add any information to each loan application. \n",
    "+ In addition, removing these columns will reduce the number of columns we'll need to explore further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pymnt_plan',\n",
       " 'initial_list_status',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'policy_code',\n",
       " 'application_type',\n",
       " 'acc_now_delinq',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'delinq_amnt',\n",
       " 'tax_liens']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_columns=[]\n",
    "for column in loans_2007.columns:\n",
    "    non_null_unique_values=len(loans_2007[column].dropna().unique())\n",
    "    if non_null_unique_values<=1:\n",
    "        drop_columns.append(column)\n",
    "loans_2007.drop(drop_columns,axis=1,inplace=True)\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by computing the number of missing values and come up with a strategy for handling them. Then, we'll focus on the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_rate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length</th>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "loan_amnt                0\n",
       "term                     0\n",
       "int_rate                 0\n",
       "installment              0\n",
       "emp_length            1036\n",
       "home_ownership           0\n",
       "annual_inc               0\n",
       "verification_status      0\n",
       "loan_status              0\n",
       "purpose                  0\n",
       "title                   11\n",
       "addr_state               0\n",
       "dti                      0\n",
       "delinq_2yrs              0\n",
       "earliest_cr_line         0\n",
       "inq_last_6mths           0\n",
       "open_acc                 0\n",
       "pub_rec                  0\n",
       "revol_bal                0\n",
       "revol_util              50\n",
       "total_acc                0\n",
       "last_credit_pull_d       2\n",
       "pub_rec_bankruptcies   697"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans = loans_2007\n",
    "null_counts=loans.isnull().sum()\n",
    "pd.DataFrame(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ While most of the columns have 0 missing values, 2 columns have 50 or less rows with missing values, and 1 column, pub_rec_bankruptcies, contains 697 rows with missing values. Let's remove columns entirely where more than 1% of the rows for that column contain a null value. In addition, we'll remove the remaining rows containing null values.\n",
    "\n",
    "+ This means that we'll keep the following columns and just remove rows containing missing values for them:\n",
    "\n",
    "+ title\n",
    "+ revol_util\n",
    "+ last_credit_pull_d\n",
    "+ and drop the pub_rec_bankruptcies column entirely since more than 1% of the rows have a missing value for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     11\n",
       "float64    10\n",
       "int64       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.drop('pub_rec_bankruptcies',axis=1,inplace=True)\n",
    "loans.dropna(axis=0,inplace=True)\n",
    "loans.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the numerical columns can be used natively with scikit-learn, the object columns that contain text need to be converted to numerical data types. Let's return a new Dataframe containing just the object columns so we can explore them in more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Verified</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term int_rate emp_length home_ownership verification_status  \\\n",
       "0   36 months   10.65%  10+ years           RENT            Verified   \n",
       "\n",
       "       purpose     title addr_state earliest_cr_line revol_util  \\\n",
       "0  credit_card  Computer         AZ         Jan-1985      83.7%   \n",
       "\n",
       "  last_credit_pull_d  \n",
       "0           Jun-2016  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns_df= loans.select_dtypes(include=['object'])\n",
    "object_columns_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Some of the columns seem like they represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    "+ home_ownership: home ownership status, can only be 1 of 4 categorical values according to the data dictionary,\n",
    "+ verification_status: indicates if income was verified by Lending Club,\n",
    "+ emp_length: number of years the borrower was employed upon time of application,\n",
    "+ term: number of payments on the loan, either 36 or 60,\n",
    "+ addr_state: borrower's state of residence,\n",
    "+ purpose: a category provided by the borrower for the loan request,\n",
    "+ title: loan title provided the borrower,\n",
    "+ There are also some columns that represent numeric values, that need to be converted:\n",
    "\n",
    "+ int_rate: interest rate of the loan in %,\n",
    "+ revol_util: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit, read more here.\n",
    "+ Based on the first row's values for purpose and title, it seems like these columns could reflect the same information. Let's explore the unique value counts separately to confirm if this is true.\n",
    "\n",
    "+ Lastly, some of the columns contain date values that would require a good amount of feature engineering for them to be potentially useful:\n",
    "\n",
    "+ earliest_cr_line: The month the borrower's earliest reported credit line was opened,\n",
    "+ last_credit_pull_d: The most recent month Lending Club pulled credit for this loan.\n",
    "+ Since these date features require some feature engineering for modeling purposes, let's remove these date columns from the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RENT        18112\n",
       "MORTGAGE    16686\n",
       "OWN          2778\n",
       "OTHER          96\n",
       "NONE            3\n",
       "Name: home_ownership, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Not Verified       16281\n",
       "Verified           11856\n",
       "Source Verified     9538\n",
       "Name: verification_status, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10+ years    8545\n",
       "< 1 year     4513\n",
       "2 years      4303\n",
       "3 years      4022\n",
       "4 years      3353\n",
       "5 years      3202\n",
       "1 year       3176\n",
       "6 years      2177\n",
       "7 years      1714\n",
       "8 years      1442\n",
       "9 years      1228\n",
       "Name: emp_length, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 36 months    28234\n",
       " 60 months     9441\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "CA    6776\n",
       "NY    3614\n",
       "FL    2704\n",
       "TX    2613\n",
       "NJ    1776\n",
       "IL    1447\n",
       "PA    1442\n",
       "VA    1347\n",
       "GA    1323\n",
       "MA    1272\n",
       "OH    1149\n",
       "MD    1008\n",
       "AZ     807\n",
       "WA     788\n",
       "CO     748\n",
       "NC     729\n",
       "CT     711\n",
       "MI     678\n",
       "MO     648\n",
       "MN     581\n",
       "NV     466\n",
       "SC     454\n",
       "WI     427\n",
       "OR     422\n",
       "AL     420\n",
       "LA     420\n",
       "KY     311\n",
       "OK     285\n",
       "UT     249\n",
       "KS     249\n",
       "AR     229\n",
       "DC     209\n",
       "RI     194\n",
       "NM     180\n",
       "WV     164\n",
       "HI     162\n",
       "NH     157\n",
       "DE     110\n",
       "MT      77\n",
       "WY      76\n",
       "AK      76\n",
       "SD      60\n",
       "VT      53\n",
       "MS      19\n",
       "TN      17\n",
       "IN       9\n",
       "ID       6\n",
       "NE       5\n",
       "IA       5\n",
       "ME       3\n",
       "Name: addr_state, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for c in cols:\n",
    "    loans[c].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The home_ownership, verification_status, emp_length, term, and addr_state columns all contain multiple discrete values. We should clean the emp_length column and treat it as a numerical one since the values have ordering (2 years of employment is less than 8 years).\n",
    "\n",
    "+ First, let's look at the unique value counts for the purpose and title columns to understand which column we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debt_consolidation    17751\n",
       "credit_card            4911\n",
       "other                  3711\n",
       "home_improvement       2808\n",
       "major_purchase         2083\n",
       "small_business         1719\n",
       "car                    1459\n",
       "wedding                 916\n",
       "medical                 655\n",
       "moving                  552\n",
       "house                   356\n",
       "vacation                348\n",
       "educational             312\n",
       "renewable_energy         94\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Debt Consolidation                          2068\n",
       "Debt Consolidation Loan                     1599\n",
       "Personal Loan                                624\n",
       "Consolidation                                488\n",
       "debt consolidation                           466\n",
       "Credit Card Consolidation                    345\n",
       "Home Improvement                             336\n",
       "Debt consolidation                           314\n",
       "Small Business Loan                          298\n",
       "Credit Card Loan                             294\n",
       "Personal                                     290\n",
       "Consolidation Loan                           250\n",
       "Home Improvement Loan                        228\n",
       "personal loan                                219\n",
       "Loan                                         202\n",
       "Wedding Loan                                 199\n",
       "personal                                     198\n",
       "Car Loan                                     188\n",
       "consolidation                                186\n",
       "Other Loan                                   168\n",
       "Wedding                                      148\n",
       "Credit Card Payoff                           144\n",
       "Credit Card Refinance                        140\n",
       "Major Purchase Loan                          131\n",
       "Consolidate                                  124\n",
       "Medical                                      111\n",
       "Credit Card                                  110\n",
       "home improvement                             101\n",
       "Credit Cards                                  91\n",
       "My Loan                                       90\n",
       "                                            ... \n",
       "Discovery                                      1\n",
       "Better deal                                    1\n",
       "Cathy's Debt Cons Loan                         1\n",
       "Consolidate CCs and pay back family            1\n",
       "Freedom from Debt!!!!                          1\n",
       "Consolidate Macy's and Citi Cards              1\n",
       "Javier Payment                                 1\n",
       "Pay off cancelled wedding                      1\n",
       "Solidly employed and seeking a refinance       1\n",
       "Car financing/ Vacation                        1\n",
       "Honda Aquatrax                                 1\n",
       "Debt Consolidation and Home Repair 09/09       1\n",
       "people not banks                               1\n",
       "Excellent Loan                                 1\n",
       "350 Rich. Terrace                              1\n",
       "Cc consolidation                               1\n",
       "Fencing Property                               1\n",
       "magna                                          1\n",
       "25K Credit Consolidation Loan                  1\n",
       "A Single Payment                               1\n",
       "medical & taxes                                1\n",
       "Lawn maintenance business                      1\n",
       "Consolidate Store Credit Cards                 1\n",
       "Pay Off AmEx                                   1\n",
       "Education loan for Masters                     1\n",
       "The Life Changer                               1\n",
       "Building my families future                    1\n",
       "Mini Vacation                                  1\n",
       "GET OUT OF DEPT                                1\n",
       "getting out of debt                            1\n",
       "Name: title, Length: 18881, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans[\"purpose\"].value_counts()\n",
    "loans[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The home_ownership, verification_status, emp_length, and term columns each contain a few discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "+ It seems like the purpose and title columns do contain overlapping information but we'll keep the purpose column since it contains a few discrete values. In addition, the title column has data quality issues since many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation).\n",
    "\n",
    "+ We can use the following mapping to clean the emp_length column:\n",
    "\n",
    "+ \"10+ years\": 10\n",
    "+ \"9 years\": 9\n",
    "+ \"8 years\": 8\n",
    "+ \"7 years\": 7\n",
    "+ \"6 years\": 6\n",
    "+ \"5 years\": 5\n",
    "+ \"4 years\": 4\n",
    "+ \"3 years\": 3\n",
    "+ \"2 years\": 2\n",
    "+ \"1 year\": 1\n",
    "+ \"< 1 year\": 0\n",
    "+ \"n/a\": 0\n",
    "+ We erred on the side of being conservative with the 10+ years, < 1 year and n/a mappings. We assume that people who may have been working more than 10 years have only really worked for 10 years. We also assume that people who've worked less than a year or if the information is not available that they've worked for 0. This is a general heuristic but it's not perfect.\n",
    "\n",
    "+ Lastly, the addr_state column contains many discrete values and we'd need to add 49 dummy variable columns to use it for classification. This would make our Dataframe much larger and could slow down how quickly the code runs. Let's remove this column from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "loans.drop(['last_credit_pull_d','addr_state','title','earliest_cr_line'],axis=1,inplace=True)\n",
    "loans['int_rate']=loans['int_rate'].str.rstrip('%')\n",
    "loans['int_rate']=loans['int_rate'].astype(float)\n",
    "loans['revol_util']=loans['revol_util'].str.rstrip('%')\n",
    "loans['revol_util']=loans['revol_util'].astype(float)\n",
    "loans=loans.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now encode the home_ownership, verification_status, purpose, and term columns as dummy variables so we can use them in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dataframe=pd.get_dummies(loans[['home_ownership','verification_status','purpose','term']])\n",
    "loans=pd.concat([loans,dummy_dataframe],axis=1)\n",
    "loans.drop(['home_ownership','verification_status','purpose','term'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We established that this is a binary classification problem in the first mission of this course, and we converted the loan_status column to 0s and 1s as a result. Before diving in and selecting an algorithm to apply to the data, we should select an error metric.\n",
    "\n",
    "+ An error metric will help us figure out when our model is performing well, and when it's performing poorly. To tie error metrics all the way back to the original question we wanted to answer, let's say we're using a machine learning model to predict whether or not we should fund a loan on the Lending Club platform. Our objective in this is to make money -- we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. An error metric will help us determine if our algorithm will make us money or lose us money.\n",
    "\n",
    "+ In this case, we're primarily concerned with false positives and false negatives. Both of these are different types of misclassifications. With a false positive, we predict that a loan will be paid off on time, but it actually isn't. This costs us money, since we fund loans that lose us money. With a false negative, we predict that a loan won't be paid off on time, but it actually would be paid off on time. This loses us potential money, since we didn't fund a loan that actually would have been paid off.\n",
    "\n",
    "+ Since we're viewing this problem from the standpoint of a conservative investor, we need to treat false positives differently than false negatives. A conservative investor would want to minimize risk, and avoid false positives as much as possible. They'd be more okay with missing out on opportunities (false negatives) than they would be with funding a risky loan (false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalances\n",
    "+ We mentioned earlier that there is a significant class imbalance in the loan_status column. There are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0). This causes a major issue when we use accuracy as a metric. This is because due to the class imbalance, a classifier can predict 1 for every row, and still have high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ A good first algorithm to apply to binary classification problems is logistic regression, for the following reasons:\n",
    "\n",
    "+ it's quick to train and we can iterate more quickly,\n",
    "+ it's less prone to overfitting than more complex models like decision trees,\n",
    "+ it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = loans.drop('loan_status',axis=1)\n",
    "target = loans['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 10, 1: 1}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty= {0:10,1:1}\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "lr.fit(X_train,y_train)\n",
    "predictions=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4826</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1006    96\n",
       "1  4826  1607"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_logist = 98/(98+1004)*100\n",
    "tpr_logist = 1621/(1621+4812)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.892921960072595"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "25.19819679776154"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_logist\n",
    "tpr_logist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.397693817468106"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fone_logist = f1_score(y_test,predictions)\n",
    "fone_logist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9429901105293775"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_logist = precision_score(y_test,predictions)\n",
    "precision_logist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Our best model had a false positive rate of 8%, and a true positive rate of 25%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 8% of borrowers defaulting, and that the pool of 25% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "+ If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would. Given this, there's still quite a bit of room to improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = XGBClassifier(class_weight={0:50,1:1})\n",
    "param_xgboost = {'gamma':[0,0.01,0.05,0.1,1,5,10,20],'learning_rate':[0,0.01,0.05,0.1,0.5],'max_depth':[3,4,5,6,7,8,9,10,20],'n_estimators':[100,150,200,300,400]}\n",
    "xgb_search = RandomizedSearchCV(xgb_classifier, param_distributions = param_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', class_weight={0: 50, 1: 1},\n",
       "       colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'gamma': [0, 0.01, 0.05, 0.1, 1, 5, 10, 20], 'learning_rate': [0, 0.01, 0.05, 0.1, 0.5], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 20], 'n_estimators': [100, 150, 200, 300, 400]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = xgb_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>6420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1\n",
       "0   8  1094\n",
       "1  13  6420"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.514804</td>\n",
       "      <td>0.098985</td>\n",
       "      <td>0.081051</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.842441</td>\n",
       "      <td>0.854384</td>\n",
       "      <td>0.848099</td>\n",
       "      <td>0.848308</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>7</td>\n",
       "      <td>0.903847</td>\n",
       "      <td>0.875280</td>\n",
       "      <td>0.894944</td>\n",
       "      <td>0.891357</td>\n",
       "      <td>0.011935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.897320</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.107180</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.857768</td>\n",
       "      <td>0.857968</td>\n",
       "      <td>0.857157</td>\n",
       "      <td>0.857631</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>2</td>\n",
       "      <td>0.861345</td>\n",
       "      <td>0.860748</td>\n",
       "      <td>0.860954</td>\n",
       "      <td>0.861015</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.352883</td>\n",
       "      <td>0.304598</td>\n",
       "      <td>1.222553</td>\n",
       "      <td>0.019668</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 20, 'learni...</td>\n",
       "      <td>0.853986</td>\n",
       "      <td>0.854783</td>\n",
       "      <td>0.855266</td>\n",
       "      <td>0.854678</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.689645</td>\n",
       "      <td>0.205856</td>\n",
       "      <td>0.160910</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>0.856076</td>\n",
       "      <td>0.856276</td>\n",
       "      <td>0.857655</td>\n",
       "      <td>0.856669</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>4</td>\n",
       "      <td>0.877221</td>\n",
       "      <td>0.872145</td>\n",
       "      <td>0.872101</td>\n",
       "      <td>0.873822</td>\n",
       "      <td>0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.199216</td>\n",
       "      <td>0.444288</td>\n",
       "      <td>0.095127</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.142232</td>\n",
       "      <td>0.142232</td>\n",
       "      <td>0.142246</td>\n",
       "      <td>0.142236</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.142232</td>\n",
       "      <td>0.142236</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.082724</td>\n",
       "      <td>1.184759</td>\n",
       "      <td>0.041996</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 10, 'learni...</td>\n",
       "      <td>0.845825</td>\n",
       "      <td>0.846919</td>\n",
       "      <td>0.843818</td>\n",
       "      <td>0.845521</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>8</td>\n",
       "      <td>0.899716</td>\n",
       "      <td>0.899716</td>\n",
       "      <td>0.910521</td>\n",
       "      <td>0.903318</td>\n",
       "      <td>0.005093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.989028</td>\n",
       "      <td>0.113226</td>\n",
       "      <td>0.280649</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 9, 'learnin...</td>\n",
       "      <td>0.853489</td>\n",
       "      <td>0.855778</td>\n",
       "      <td>0.856261</td>\n",
       "      <td>0.855176</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>5</td>\n",
       "      <td>0.921266</td>\n",
       "      <td>0.916687</td>\n",
       "      <td>0.914353</td>\n",
       "      <td>0.917435</td>\n",
       "      <td>0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.970976</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.857569</td>\n",
       "      <td>0.858067</td>\n",
       "      <td>0.857456</td>\n",
       "      <td>0.857697</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862987</td>\n",
       "      <td>0.860897</td>\n",
       "      <td>0.861800</td>\n",
       "      <td>0.861894</td>\n",
       "      <td>0.000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.561990</td>\n",
       "      <td>0.144382</td>\n",
       "      <td>0.203596</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>0.142232</td>\n",
       "      <td>0.142232</td>\n",
       "      <td>0.142246</td>\n",
       "      <td>0.142236</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.142232</td>\n",
       "      <td>0.142236</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47.271279</td>\n",
       "      <td>0.152171</td>\n",
       "      <td>0.480116</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 10, 'learni...</td>\n",
       "      <td>0.856276</td>\n",
       "      <td>0.857171</td>\n",
       "      <td>0.857456</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>3</td>\n",
       "      <td>0.873986</td>\n",
       "      <td>0.870403</td>\n",
       "      <td>0.870110</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>0.001762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      15.514804      0.098985         0.081051        0.017921   \n",
       "1      11.897320      0.054904         0.107180        0.002459   \n",
       "2      65.352883      0.304598         1.222553        0.019668   \n",
       "3      13.689645      0.205856         0.160910        0.000970   \n",
       "4      16.199216      0.444288         0.095127        0.003202   \n",
       "5      21.082724      1.184759         0.041996        0.002952   \n",
       "6      19.989028      0.113226         0.280649        0.002459   \n",
       "7       5.970976      0.019282         0.063407        0.000601   \n",
       "8      24.561990      0.144382         0.203596        0.002015   \n",
       "9      47.271279      0.152171         0.480116        0.005393   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate param_gamma  \\\n",
       "0                400               3                 0.5           1   \n",
       "1                300               3                0.05           0   \n",
       "2                300              20                0.05           0   \n",
       "3                200               6                0.05         0.1   \n",
       "4                400               3                   0           5   \n",
       "5                200              10                 0.5           5   \n",
       "6                200               9                0.05           1   \n",
       "7                100               5                0.05        0.05   \n",
       "8                300               7                   0         0.1   \n",
       "9                400              10                0.01           5   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'n_estimators': 400, 'max_depth': 3, 'learnin...           0.842441   \n",
       "1  {'n_estimators': 300, 'max_depth': 3, 'learnin...           0.857768   \n",
       "2  {'n_estimators': 300, 'max_depth': 20, 'learni...           0.853986   \n",
       "3  {'n_estimators': 200, 'max_depth': 6, 'learnin...           0.856076   \n",
       "4  {'n_estimators': 400, 'max_depth': 3, 'learnin...           0.142232   \n",
       "5  {'n_estimators': 200, 'max_depth': 10, 'learni...           0.845825   \n",
       "6  {'n_estimators': 200, 'max_depth': 9, 'learnin...           0.853489   \n",
       "7  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.857569   \n",
       "8  {'n_estimators': 300, 'max_depth': 7, 'learnin...           0.142232   \n",
       "9  {'n_estimators': 400, 'max_depth': 10, 'learni...           0.856276   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.854384           0.848099         0.848308        0.004878   \n",
       "1           0.857968           0.857157         0.857631        0.000345   \n",
       "2           0.854783           0.855266         0.854678        0.000528   \n",
       "3           0.856276           0.857655         0.856669        0.000702   \n",
       "4           0.142232           0.142246         0.142236        0.000007   \n",
       "5           0.846919           0.843818         0.845521        0.001284   \n",
       "6           0.855778           0.856261         0.855176        0.001209   \n",
       "7           0.858067           0.857456         0.857697        0.000265   \n",
       "8           0.142232           0.142246         0.142236        0.000007   \n",
       "9           0.857171           0.857456         0.856967        0.000503   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.903847            0.875280   \n",
       "1                2            0.861345            0.860748   \n",
       "2                6            1.000000            1.000000   \n",
       "3                4            0.877221            0.872145   \n",
       "4                9            0.142239            0.142239   \n",
       "5                8            0.899716            0.899716   \n",
       "6                5            0.921266            0.916687   \n",
       "7                1            0.862987            0.860897   \n",
       "8                9            0.142239            0.142239   \n",
       "9                3            0.873986            0.870403   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.894944          0.891357         0.011935  \n",
       "1            0.860954          0.861015         0.000248  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.872101          0.873822         0.002403  \n",
       "4            0.142232          0.142236         0.000003  \n",
       "5            0.910521          0.903318         0.005093  \n",
       "6            0.914353          0.917435         0.002872  \n",
       "7            0.861800          0.861894         0.000856  \n",
       "8            0.142232          0.142236         0.000003  \n",
       "9            0.870110          0.871500         0.001762  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(xgb_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9206280920628093"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search_fone = f1_score(y_test, new_preds)\n",
    "xgb_search_fone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight={0: 50, 1: 1},\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=None, oob_score=False,\n",
       "            random_state=1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 50, 100, 200], 'max_depth': [3, 5, 6, 7, 8, 9, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "rf= RandomForestClassifier(random_state=1, class_weight={0:50,1:1})\n",
    "parameters_rf = {'n_estimators':[10,50,100,200],'max_depth':[3,5,6,7,8,9,20]}\n",
    "rf_search = GridSearchCV(rf,param_grid = parameters_rf)\n",
    "rf_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf=rf_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>664</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2561</td>\n",
       "      <td>3872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0   664   438\n",
       "1  2561  3872"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, preds_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (Multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier4 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = classifier4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>634</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2781</td>\n",
       "      <td>3652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0   634   468\n",
       "1  2781  3652"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to scale the features because the algorithms we are going to apply next are all sensitive to euclidean distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_transform = scaler.fit_transform(X_train)\n",
    "X_test_transform = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier5 = SVC(class_weight={0:0.9,1:0.1},C = 7.0,kernel = 'rbf',gamma=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37675, 37)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier5.fit(X_train_transform,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds5 = classifier5.predict(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1\n",
       "0  0  1102\n",
       "1  0  6433"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We decided to create an ensemble of our Logistic model, the Random Forests model and the Naive Bayes model\n",
    "+ The ensemble predictions will be calculated using majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred =[]\n",
    "for i in range(0,len(X_test)):\n",
    "    final_pred.append(mode([predictions[i], preds_rf[i], preds4[i]])[0])\n",
    "final_pred = np.array(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>826</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3493</td>\n",
       "      <td>2940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0   826   276\n",
       "1  3493  2940"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, final_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
